# Quick Start

This guide will walk you through running your first AgentX applications, from a simple, single-agent chat to a more complex multi-agent team.

import { Callout } from "nextra-theme-docs";

## Prerequisites

Before you begin, make sure you have AgentX installed and have configured your LLM API keys as environment variables (e.g., `DEEPSEEK_API_KEY`).

<Callout type="warning" emoji="âš ï¸">
  Make sure to set your API keys as environment variables before running the
  examples.
</Callout>

## Installation

```bash
pip install agentx
```

## Example 1: Simple Chat (Single Agent)

This example demonstrates the simplest use case: a direct conversation with a single, tool-equipped AI assistant. It uses the `start_task` and `task.step()` functions for an interactive, turn-by-turn conversation.

### 1. The Code

This Python script sets up an interactive chat loop.

```python
#!/usr/bin/env python3
import asyncio
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent.parent / "src"))

from agentx import start_task

async def main():
    print("ðŸ¤– AgentX Chat (type 'quit' to exit)\\n")
    task = start_task("hi")
    user_input = None

    while not task.is_complete:
        print("ðŸ¤– Assistant: ", end="", flush=True)

        async for chunk in task.step(user_input=user_input, stream=True):
            if chunk.get("type") == "content":
                print(chunk.get("content", ""), end="", flush=True)

        if not task.is_complete:
            user_input = input("ðŸ‘¤ You: ").strip()

if __name__ == "__main__":
    asyncio.run(main())
```

### 2. The Configuration

This YAML file defines the "team," which in this case is just a single agent. It defines the agent's prompt, gives it a web search tool, and configures the LLM.

```yaml
name: "simple_chat"
description: "A simple chat example with user, assistant, search, and memory"

agents:
  - name: "assistant"
    description: "Helpful AI assistant with search capabilities"
    prompt_template: "prompts/assistant.md"
    tools: ["web_search"]
    llm_config:
      provider: "deepseek"
      model: "deepseek-chat"

tools:
  - name: "web_search"
    type: "builtin"
```

<Callout type="info" emoji="ðŸ’¡">
  The configuration uses YAML for simplicity and readability. You can define
  agents, tools, and their relationships declaratively.
</Callout>

## Example 2: Multi-Agent Collaboration

This example showcases AgentX's multi-agent capabilities. A `Writer` agent drafts an article, and then a `Reviewer` agent provides feedback. The handoff between them is managed automatically by the `TaskExecutor` based on natural language conditions.

### 1. The Code

```python
#!/usr/bin/env python3
import asyncio
import sys
from pathlib import Path

project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root / "src"))

from agentx import execute_task

async def main():
    config_path = str(Path(__file__).parent / "config" / "team.yaml")
    prompt = "Write a short article about remote work benefits."

    async for update in execute_task(prompt, config_path, stream=True):
        update_type = update.get("type")

        if update_type == "content":
            print(update["content"], end="", flush=True)
        elif update_type == "handoff":
            print(f"\\n\\nðŸ”„ HANDOFF: {update['from_agent']} â†’ {update['to_agent']}\\n")

if __name__ == "__main__":
    asyncio.run(main())
```

### 2. The Multi-Agent Configuration

This configuration defines two agents and the handoff rules that govern their collaboration:

```yaml
name: "WriterReviewerTeam"
agents:
  - name: writer
    description: "Professional content writer for creating high-quality articles"
    prompt_template: "prompts/writer.md"
    llm_config:
      model: deepseek/deepseek-chat

  - name: reviewer
    description: "Quality assurance specialist for reviewing and improving content"
    prompt_template: "prompts/reviewer.md"
    llm_config:
      model: deepseek/deepseek-chat

# Handoffs using natural language conditions
handoffs:
  - from_agent: "writer"
    to_agent: "reviewer"
    condition: "draft is complete and ready for review"

  - from_agent: "reviewer"
    to_agent: "writer"
    condition: "feedback has been provided and revisions are needed"
```

<Callout type="success" emoji="âœ¨">
  Notice how handoffs use natural language conditions! AgentX intelligently
  determines when to transfer control between agents.
</Callout>

## Next Steps

- Explore the [Architecture](/architecture) to understand how AgentX works
- Check out more [Examples](/examples) for advanced use cases
- Dive into the [API Reference](/api) for detailed documentation
