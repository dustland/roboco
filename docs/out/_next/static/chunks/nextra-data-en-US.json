{"/arch/00-requirements":{"title":"AgentX Framework: Core Requirements","data":{"":"1.  File-Based Configuration: The entire multi-agent team structure and collaboration workflow are defined in and loaded from static, file-based configurations (e.g., team.yaml). These configurations serve as the complete, declarative definition of a team.\n2.  Orchestrator as Central Controller: The Orchestrator is the primary entry point and central controller for a task. It is responsible for managing the flow of the collaboration, not its content. Its duties include accepting the initial prompt, determining the next agent to act, dispatching tool calls, and terminating the collaboration based on defined conditions.\n3.  Team State Management: The framework maintains a persistent, file-based state for each task execution. This includes the conversation history, current agent, round count, artifacts, and other execution metadata stored in the task workspace.\n4.  Agent Prompt Templates: Each agent's behavior is defined by a Jinja2 template file that specifies its role, instructions, and context. The framework renders these templates with dynamic context (history, available tools, task prompt) to generate the agent's system prompt.\n5.  Comprehensive Data Structures: The framework uses well-defined Pydantic models for all data structures including TaskStep, ToolCall, ToolResult, Artifact, and various event types. These provide type safety, validation, and serialization.\n6.  Event-Driven Architecture: The framework emits structured events for all significant execution milestones (task start/complete, agent turns, tool calls, handoffs, errors) enabling monitoring, debugging, and integration with external systems.\n7.  Message Streaming Support: Separate from execution events, the framework supports real-time message streaming for UI updates, allowing clients to receive incremental content as it's generated by agents.\n8.  Workspace Management: Each task execution gets its own workspace directory containing state files, artifacts, history logs, and other task-specific data. This enables task persistence, resumption, and artifact management.\n9.  Tool Integration: The framework supports multiple tool types (builtin, python functions, MCP tools, HITL tools) with a unified interface. Tools are configured declaratively and can be shared across agents or restricted to specific agents.\n10. LLM Provider Abstraction: The framework abstracts LLM interactions through a unified interface supporting multiple providers (OpenAI, Anthropic, DeepSeek, Ollama, custom) with provider-specific optimizations and fallback mechanisms.\n11. Handoff Rules: Agent-to-agent handoffs are governed by explicit rules defined in the team configuration. These rules specify conditions, target agents, and handoff types (sequential, parallel) enabling sophisticated collaboration patterns.\n12. Memory Management: The framework provides both short-term (conversation context) and long-term (persistent) memory with semantic search capabilities. Memory operations are tracked and can be queried for debugging and optimization.\n13. Guardrails and Safety: Comprehensive safety mechanisms including input validation, output filtering, rate limiting, and content safety checks. Guardrail policies are configurable per agent and can block, warn, or log violations.\n14. Human-in-the-Loop (HITL): Built-in support for human intervention points through step-through execution mode, allowing users to pause execution, inspect state, modify context, and provide input at any point in the workflow.\n15. Step-Through Debugging: The framework supports step-by-step execution with breakpoints, allowing developers to pause execution, inspect state, modify context, and resume. Essential for development and debugging complex workflows.\n16. Production Deployment: The framework includes deployment configurations, health checks, performance monitoring, and scaling capabilities for production environments including containerization and cloud deployment support.\n17. Favor DeepSeek Models: The framework defaults to DeepSeek models for reasoning and general scenarios, with easy configuration for other providers when needed.\n18. Autonomous Task Execution: The framework can execute tasks autonomously from start to completion, making intelligent decisions about agent handoffs, tool usage, and task termination without human intervention.\n19. Advanced Workspace Management: Sophisticated workspace system with semantic search, automatic consolidation, and intelligent context management to maintain relevant information across long conversations.\n20. Rich Artifact Management: Advanced artifact handling including versioning, metadata tracking, cross-references, and support for various media types (code, documents, images, data).\n21. Intelligent Context Management: Smart context compilation strategies, automatic summarization, and relevance-based filtering to optimize LLM context usage and maintain conversation coherence."}},"/arch/02-state-and-context":{"title":"State and Context: Enabling Complex, Long-Running Tasks","data":{"":"A key challenge in building autonomous AI systems is managing state. For an agent to perform complex, multi-step tasks like writing a novel or developing a software project, it needs a reliable, long-term memory of its work. This document outlines AgentX's state and context architecture, which is designed specifically to address the hard problems of contextual understanding in large-scale tasks.","1-the-core-challenges-of-stateful-ai#1. The Core Challenges of Stateful AI":"Before detailing the architecture, it's crucial to understand the specific challenges AgentX aims to solve. Effective state and context management must address the following:\nNavigating Large and Complex Workspaces: A significant project, whether it's a codebase or a research archive, can contain hundreds or thousands of files. An agent cannot simply \"list all files\" and be effective. It needs a way to understand the project's structure, identify key artifacts, and navigate the workspace intelligently without being overwhelmed.\nProcessing Long-Form Content: A single artifact, like a legacy source code file or a detailed technical paper, can be thousands of lines long‚Äîfar exceeding the context window of any LLM. An agent tasked with refactoring a large file or summarizing a dense document cannot simply \"read the file.\" It needs a mechanism to process content in a way that preserves the overall structure and meaning.\nContextual Scoping and Filtering: Agents often start with a vast pool of raw data, such as gigabytes of financial reports for a market analysis. The critical challenge is to narrow down this \"firehose of information\" to a small, relevant subset of data that is actually valuable for the task at hand. An agent writing a research summary needs to intelligently select its sources, not just process all of them.\nBalancing Performance with Quality: While quality is paramount, system performance cannot be ignored. A system that is perfectly thorough but takes hours to respond is impractical. We need an architecture that provides high-quality, relevant context to the agent in a timely manner, making smart trade-offs between exhaustive search and responsive interaction.\nAutomated Quality Assessment: How does the system know if a generated artifact is \"good\"? For code, this could mean passing linting checks, compiling successfully, or passing unit tests. For a document, it might mean checking for spelling errors or grammatical correctness. The system needs a mechanism to automatically assess the quality of its own outputs to guide the iterative process.","2-the-architecture-a-two-layered-solution#2. The Architecture: A Two-Layered Solution":"AgentX addresses these challenges with a two-layered architecture: The Workspace provides a durable, comprehensive record of the task, while the Memory System provides the intelligent interface for navigating and understanding it.","21-layer-1-the-workspace---a-durable-version-controlled-record#2.1. Layer 1: The Workspace - A Durable, Version-Controlled Record":"The Workspace is the single source of truth for a task. By creating a version-controlled directory containing every message, artifact, and state change, it directly addresses the need for a complete and traceable history.\nSolution for Navigating Large Workspaces: While the Workspace stores everything, agents interact with it via tools. Tools like list_directory combined with an agent's reasoning allow it to explore the structure of the workspace step-by-step, rather than being flooded with a list of thousands of files at once.\nFoundation for Quality Assessment: By providing a stable location for artifacts (e.g., main.py), the Workspace enables the creation of quality assessment tools. A linting_tool or build_tool can be pointed at artifacts in the Workspace to check their integrity, providing structured feedback that the agent can act upon.","22-layer-2-the-memory-system---an-intelligent-knowledge-base#2.2. Layer 2: The Memory System - An Intelligent Knowledge Base":"The Memory System is not merely a passive query layer but a sophisticated, multi-faceted knowledge base that sits on top of the Workspace. It proactively transforms the raw, version-controlled data into actionable intelligence for the agents. Its responsibilities are threefold:\n1. Semantic Indexing and Retrieval (Cold Data Querying): This is the foundational capability. The Memory System indexes the entire contents of the Workspace, allowing agents to perform fast, semantic searches over vast amounts of \"cold\" data. This solves the problem of processing long-form content by allowing an agent to find relevant snippets (e.g., \"Find functions in services.py related to payment processing\") without loading entire files into its context window.\n2. Intelligent Summarization and Abstraction: The Memory System can synthesize information to provide high-level, abstract summaries on demand. For example, an agent can ask it to generate a \"virtual README\" for a directory it has never seen before, or to summarize the key decisions from a long conversation history. This allows agents to quickly orient themselves in complex environments without needing to read every single line of source material.\n3. Proactive Knowledge Synthesis (Rules, Constraints, and Hot-Issues): This is the system's most advanced function, where it acts as a true cognitive partner. It goes beyond analyzing workspace data to internalize user instructions and preferences, creating a set of rules and guardrails for the agent's behavior.\nCapturing User Constraints: The system is designed to capture and enforce high-level user constraints that persist across interactions. If a user states, \"When writing about Tesla's future, never mention Elon Musk,\" the Memory System records this as a core project requirement. This rule is then used to guide content generation and validation, ensuring the final output adheres to the user's explicit directive.\nLearning from Feedback: It learns from iterative feedback to codify developer or user preferences. When a developer says, \"You should never create a requirements.txt file; use pyproject.toml instead,\" the Memory System flags this as a permanent rule for all future file operations in that workspace. This prevents the agent from repeating mistakes or asking redundant questions.\nTracking Hot-Issues: It maintains a \"working memory\" of transient problems. For instance, if a unit test fails, the Memory System flags it as a \"hot issue\" that is automatically surfaced in the agent's context on every subsequent step until it is resolved. This prevents critical blockers from being lost in a long history.","3-example-workflow-revisited-solving-problems-in-practice#3. Example Workflow Revisited: Solving Problems in Practice":"Consider the workflow of an agent tasked with adding a feature to a large, existing codebase, but this time using the full power of the intelligent Memory System.\nChallenge - Capturing Constraints: The user starts by saying, \"I'm getting a strange bug related to caching, so for now, please add a @disable_cache decorator to any new data-fetching functions you write.\" The Memory System logs Rule: Must add '@disable_cache' to new data-fetching functions.\nChallenge - Navigating the Workspace: The agent doesn't know the code structure. It asks, summarize_directory_purpose(path='/src/api'). The Memory System synthesizes a description, and also surfaces the active rule about caching.\nChallenge - Processing Long-Form Content: The agent identifies a large services.py file and uses search_memory(query='Find functions in services.py related to user data') to get the relevant snippets.\nChallenge - Quality Assessment & Hot-Issue Tracking: After writing a new function to the file, the agent calls run_unit_tests_tool(). The test fails. The Memory System detects this and creates a high-priority \"hot issue\": Critical: Unit test 'test_new_feature' is failing.\nFocused Iteration: On the agent's next reasoning cycle, two items are injected into its context: the Rule about the decorator and the Hot-Issue about the failing test. The agent sees the code it wrote is missing the decorator. It adds it, confident this will fix the issue.\nResolution: The agent runs the tests again. They pass. The Memory System sees the success event, automatically resolves and removes the \"hot issue,\" and the task proceeds. The rule about the decorator remains active.\nThis workflow, grounded in a state and context architecture powered by an intelligent knowledge base, demonstrates how AgentX provides a practical and scalable solution to the core challenges of building sophisticated, stateful AI agents.","4-system-design-and-implementation#4. System Design and Implementation":"This section details the technical implementation of the Workspace and Memory System, explaining how the conceptual goals are achieved.","41-workspace-design#4.1. Workspace Design":"The Workspace is not a conceptual space but a physical directory on the filesystem, managed by a GitStorage backend.\nCore Technology: Every task workspace is a Git repository. This provides a robust, built-in mechanism for versioning, change tracking, and durability.\nDirectory Structure:\nartifacts/: This subdirectory contains all the files created or modified by agents (e.g., source code, documents, data files). This is the tangible work product of the system.\nhistory.jsonl: This file is the immutable, ground-truth log of the task. Every single event‚Äîevery user message, agent thought process, tool call, and tool result‚Äîis appended to this file as a JSON object. The system uses this for auditing, debugging, and for rebuilding the state of the Memory system if needed.\nInteraction Model: Agents do not directly execute git commands. They interact with the workspace via a clean abstraction layer: the Storage tools (read_file, write_file, list_directory). After an agent successfully executes a write_file operation, the GitStorage backend automatically commits the change to the repository with a descriptive message, creating a precise, versioned history of the work.","42-memory-system-design#4.2. Memory System Design":"The Memory System is an active component that hooks into the core event loop of the system to process information and provide context.\nCore Components:\nEvent Bus Listener: The Memory System subscribes to the central EventBus. This allows it to receive a real-time stream of all events happening within the system (e.g., UserMessageSent, ToolCallExecuted, AgentThoughtProcess).\nPluggable Memory Backend: This is the storage engine for memory objects. It can be a vector database (like Mem0) for semantic search, a relational database, or a simple file-based store. It's responsible for persisting and retrieving the memory objects created by the Synthesis Engine.\nSynthesis Engine: This is the logical core of the Memory System. It's a service that contains the business logic for creating and managing memories. It listens to events from the Event Bus and decides what actions to take.\nData and Control Flow:\nIndexing Content: When the Event Bus Listener sees a ToolCallExecuted event for a write_file operation, it triggers the Synthesis Engine. The engine, in turn, takes the content of the written file and instructs the Memory Backend to index it for future semantic search.\nCreating Rules and Hot-Issues:\nWhen a UserMessageSent event occurs, the Synthesis Engine can make an LLM call to analyze the text for imperative commands or constraints. If a constraint like \"Don't use requirements.txt\" is found, it creates a CONSTRAINT memory object and saves it to the backend.\nWhen a ToolCallExecuted event occurs with a status: FAILED and is identified as a critical failure (e.g., from a test runner tool), the Synthesis Engine creates a HOT_ISSUE memory object.\nInjecting Context: This is the critical retrieval step. Before the Orchestrator runs an agent's reasoning cycle, it makes a call to the Memory System: memory.get_relevant_context(last_user_message). The Memory System's implementation of this method is designed to always retrieve all active CONSTRAINT and HOT_ISSUE objects from its backend, in addition to performing a semantic search on the user's message. This combined payload is what gets inserted into the agent's prompt, ensuring it is always aware of the most critical rules and problems.","43-system-architecture-diagram#4.3. System Architecture Diagram":"The following diagram illustrates the data flow for how the Memory System processes events and provides context back to the agent.","5-detailed-implementation-blueprint#5. Detailed Implementation Blueprint":"This section provides implementation-level details for the key components.","51-memory-object-data-models#5.1. Memory Object Data Models":"The system uses strongly-typed data models to represent different types of memories. These can be implemented as Pydantic models or similar data classes.\nfrom pydantic import BaseModel, Field\nfrom typing import Literal, Optional\nfrom uuid import UUID, uuid4\nclass Memory(BaseModel):\n    id: UUID = Field(default_factory=uuid4)\n    type: Literal[\"CONSTRAINT\", \"HOT_ISSUE\", \"DOCUMENT_CHUNK\"]\n    content: str\n    source_event_id: Optional[UUID] = None\n    is_active: bool = True # Used to resolve hot-issues\nclass Constraint(Memory):\n    type: Literal[\"CONSTRAINT\"] = \"CONSTRAINT\"\n    # e.g., \"Do not use requirements.txt\"\nclass HotIssue(Memory):\n    type: Literal[\"HOT_ISSUE\"] = \"HOT_ISSUE\"\n    # e.g., \"Unit test 'test_payment_flow' is failing.\"\nclass DocumentChunk(Memory):\n    type: Literal[\"DOCUMENT_CHUNK\"] = \"DOCUMENT_CHUNK\"\n    source_file_path: str\n    # e.g., A chunk of text from a file.","52-core-component-interfaces-python-like-pseudocode#5.2. Core Component Interfaces (Python-like Pseudocode)":"These interfaces define the contracts between the major components.\nfrom abc import ABC, abstractmethod\n# --- Backend Interface ---\nclass MemoryBackend(ABC):\n    @abstractmethod\n    def save_memories(self, memories: list[Memory]):\n        \"\"\"Persists a list of memory objects.\"\"\"\n        pass\n    @abstractmethod\n    def get_active_rules(self) -> list[Memory]:\n        \"\"\"Returns all active CONSTRAINT and HOT_ISSUE memories.\"\"\"\n        pass\n    @abstractmethod\n    def search_documents(self, query: str, top_k: int) -> list[DocumentChunk]:\n        \"\"\"Performs semantic search over document chunks.\"\"\"\n        pass\n# --- Main System Interface ---\nclass MemorySystem:\n    def __init__(self, backend: MemoryBackend):\n        self.backend = backend\n    def get_relevant_context(self, last_user_message: str) -> str:\n        \"\"\"The primary method called by the Orchestrator.\"\"\"\n        # Implementation logic described in 5.3\n        pass\n    def on_event(self, event: Event):\n        \"\"\"The primary event handler called by the Event Bus Listener.\"\"\"\n        # Implementation logic described in 5.3\n        pass","53-key-logic-flows#5.3. Key Logic Flows":"This section details the step-by-step logic within the MemorySystem.A. Event Handling (on_event logic):\nReceive Event: The on_event method is triggered by the Event Bus Listener.\nRoute by Event Type:\nIf event.type == \"UserMessageSent\":\nConstruct an LLM prompt: \"\"\"Does the following user message contain a persistent rule, constraint, or preference for an AI assistant? If so, state the rule clearly in a single imperative sentence. If not, respond with 'N/A'.\\n\\nUser Message: \"{event.text}\"\"\"\"\nCall the LLM. If the response is not \"N/A\", create a Constraint memory object with the LLM's response as the content and save it via backend.save_memories().\nIf event.type == \"ToolCallExecuted\" and event.tool_name in [\"run_tests\", \"linter\"] and event.status == \"FAILED\":\nCreate a HotIssue memory object.\ncontent should be a summary of the failure (e.g., f\"Tool '{event.tool_name}' failed: {event.result_summary}\").\nSave it via backend.save_memories().\nIf event.type == \"ToolCallExecuted\" and event.status == \"SUCCESS\" and a related HotIssue exists:\nRetrieve the related HotIssue.\nSet is_active = False on the HotIssue object.\nSave the updated memory object.\nIf event.type == \"ToolCallExecuted\" and event.tool_name == \"write_file\":\nRead the content of the written file.\nChunk the content into manageable pieces (e.g., by paragraph or function definition).\nCreate a DocumentChunk object for each piece.\nSave them via backend.save_memories().\nB. Context Retrieval (get_relevant_context logic):\nFetch Active Rules: Call backend.get_active_rules() to get all current Constraint and HotIssue objects.\nPerform Semantic Search: Call backend.search_documents(query=last_user_message, top_k=5) to get the most relevant document chunks.\nFormat for Prompt: Combine the retrieved memories into a structured string to be injected into the agent's prompt.\nCONTEXT:\n---\nACTIVE RULES AND ISSUES:\n- [Constraint] Do not use requirements.txt.\n- [Hot Issue] Unit test 'test_payment_flow' is failing.\nRELEVANT DOCUMENT SNIPPETS:\n- [Source: src/utils.py] def payment_flow(): ...\n---\nReturn the formatted string."}},"/arch/03-tool-call":{"title":"Tool Call and Execution","data":{"1-overview-and-core-principles#1. Overview and Core Principles":"This document details the architecture for defining, executing, and managing tools within AgentX. It is designed to be secure, robust, and extensible. The core principles are:\nSecurity First: Untrusted code (LLM-generated shell commands) must never execute directly on the host machine. All tool execution is centralized and sandboxed.\nRobust Self-Correction: LLM-generated tool calls can be malformed. The system must be able to detect this, provide corrective feedback to the LLM, and allow it to fix its own mistakes.\nStructured and Extensible: All tools are strongly-typed and their schemas are automatically generated. The system is designed to easily accommodate new types of tools, including custom user-defined functions and external integrations.","2-tool-definition-and-registration#2. Tool Definition and Registration":"A \"tool\" is a capability that an agent can call. This can be a Python function or a shell command.","21-tool-definition#2.1. Tool Definition":"Python Functions: Any Python function can be turned into a tool. The function must have type hints for all its arguments and a clear docstring. The docstring is critical as it is used in the prompt to tell the agent what the tool does.\ndef write_file(path: str, content: str) -> str:\n    \"\"\"Writes content to a file at the specified path.\"\"\"\n    # ... implementation ...\n    return f\"File '{path}' written successfully.\"\nShell Commands: Shell commands are defined with a name, description, and an argument schema. The agent's LLM will generate the command string based on the arguments.","22-tool-registration-and-schema-generation#2.2. Tool Registration and Schema Generation":"Tools are made available to agents via a central ToolRegistry.\nDecorator-Based Registration: The @register_tool decorator is the primary mechanism for adding a tool to the registry.\nfrom agentx.core.tool import register_tool\n@register_tool\ndef write_file(path: str, content: str) -> str:\n    # ...\nAutomatic Schema Generation: When a function is decorated, the ToolRegistry automatically inspects its signature and docstring to create a JSON schema. This schema is what the LLM sees and uses to construct a valid tool call. For the write_file example, the generated schema would look like this:\n{\n  \"name\": \"write_file\",\n  \"description\": \"Writes content to a file at the specified path.\",\n  \"parameters\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"path\": { \"type\": \"string\" },\n      \"content\": { \"type\": \"string\" }\n    },\n    \"required\": [\"path\", \"content\"]\n  }\n}","3-the-tool-call-lifecycle#3. The Tool Call Lifecycle":"The following diagram and steps describe the end-to-end flow of a tool call, from generation to result.\nStep-by-Step Flow:\nGeneration (Agent Brain): The Orchestrator provides the Brain (LLM) with the conversation history and a list of available tool schemas. The LLM determines a tool call is needed and generates the call in a structured format (e.g., JSON).\nDelegation (Agent Core): The Agent's core logic receives the raw text from the LLM, parses out the tool call request, and delegates it to the Orchestrator for execution. The agent itself has no permission to execute tools.\nValidation (Orchestrator): The Orchestrator receives the tool call. It retrieves the corresponding schema from the ToolRegistry and validates the call. It checks for missing required arguments, incorrect types, etc.\nSelf-Correction Loop (If Validation Fails):\nIf validation fails, the Orchestrator does not attempt to run the tool.\nIt generates a structured error message (e.g., \"Validation Error: Missing required argument 'path' for tool 'write_file'\").\nThis error is sent back to the Agent, which in turn passes it back to the Brain (LLM) in the next turn.\nThe LLM now has the context of its previous failed attempt and the specific validation error, allowing it to generate a corrected tool call.\nDispatch (If Validation Succeeds): If the call is valid, the Orchestrator dispatches it to the ToolExecutor.\nSecure Execution (ToolExecutor): The ToolExecutor inspects the tool type:\nPython Function: The call is a standard Python function call. It is executed directly in the main process.\nShell Command: The command is executed inside a secure, isolated sandbox.\nResult Capturing: The ToolExecutor captures the result:\nFor Python functions, this is the return value.\nFor shell commands, this includes stdout, stderr, and the exit code.\nStructured Result: The result is packaged into a ToolResult object and returned to the Orchestrator.\nForwarding: The Orchestrator forwards the ToolResult to the originating Agent.\nContextualization: The Agent formats the result into a clear, readable format (e.g., <tool_result tool_name=\"write_file\">File 'test.txt' written successfully.</tool_result>) and adds it to the conversation history for the Brain's next turn. The LLM can then use this result to form its final response to the user.","4-security-architecture-the-sandbox#4. Security Architecture: The Sandbox":"Executing arbitrary, LLM-generated shell commands is a major security risk. AgentX mitigates this by using a sandboxed execution environment.\nTechnology: The default implementation uses Docker containers. Each shell tool execution spins up a new, short-lived container.\nIsolation:\nNetwork: Containers run with networking disabled by default (--net=none) to prevent exfiltration of data or attacks on the local network. Tools that explicitly need network access must be granted it.\nFilesystem: The container is only granted access to the current task's workspace directory (/app/workspace). It cannot read from or write to any other part of the host filesystem.\nPermissions: The process inside the container runs as a non-root user to limit its privileges even within the sandbox.","5-extensibility#5. Extensibility":"","51-custom-and-built-in-tools#5.1. Custom and Built-in Tools":"Built-in Tools: AgentX provides a core set of safe tools for file I/O, search, etc., located in src/agentx/builtin_tools/.\nCustom Tools: Users can easily define their own tools in their project's codebase. As long as the file is imported and the functions are decorated with @register_tool, they will be available to the agents.","52-mcp-multi-agent-communication-protocol-integration#5.2. MCP (Multi-Agent Communication Protocol) Integration":"The tool architecture is extensible to other protocols. An MCP tool could be implemented as a special Python function:\n@register_tool\ndef send_mcp_message(recipient_agent: str, message_body: str):\n    \"\"\"Sends a message to another agent using the MCP protocol.\"\"\"\n    # Logic to connect to MCP broker and send message\n    # ...\nTo the Orchestrator and Agent, this is just another tool. The implementation details are abstracted away."}},"/arch/04-communication":{"title":"Communication and Message Architecture","data":{"1-core-principles#1. Core Principles":"The communication architecture in AgentX is designed to be robust, extensible, and streamable, drawing inspiration from modern standards like the Vercel AI SDK. The core principles are:\nMessage-Oriented: The fundamental unit of communication is a Message. All interactions, whether from a user, an agent, or a tool, are encapsulated in this structure.\nComposable Parts: A Message is composed of a list of Part objects. This allows for rich, multi-modal content and a clear separation of concerns (e.g., text, tool calls, and tool results all have their own part type).\nStreaming First: The entire model is designed for real-time streaming. A Message and its Parts can be sent incrementally, allowing for responsive user interfaces and efficient data flow.","2-the-message-and-part-schema#2. The Message and Part Schema":"This section defines the core data structures for communication.","21-the-message-object#2.1. The Message Object":"A Message represents a single entry in the conversation history. It contains a list of Part objects that make up its content.\nfrom pydantic import BaseModel, Field\nfrom typing import List, Union, Literal, Dict, Any\nimport uuid\nclass Message(BaseModel):\n    \"\"\"\n    Represents a single message in the conversation, composed of multiple parts.\n    \"\"\"\n    id: str = Field(default_factory=lambda: f\"msg_{uuid.uuid4().hex}\")\n    role: Literal[\"user\", \"assistant\"]\n    parts: List[Union[\n        \"TextPart\",\n        \"ToolCallPart\",\n        \"ToolResultPart\",\n        \"ToolErrorPart\"\n    ]]","22-the-part-objects#2.2. The Part Objects":"These are the building blocks of a Message.","textpart#TextPart":"The simplest part, containing a piece of text. During streaming, multiple TextPart objects can be sent to represent a continuous flow of text.\nclass TextPart(BaseModel):\n    type: Literal[\"text\"] = \"text\"\n    text: str","toolcallpart#ToolCallPart":"A structured request from an agent to call a specific tool with a given set of arguments.\nclass ToolCallPart(BaseModel):\n    type: Literal[\"tool_call\"] = \"tool_call\"\n    tool_call_id: str = Field(default_factory=lambda: f\"tc_{uuid.uuid4().hex}\")\n    tool_name: str\n    args: Dict[str, Any]","toolresultpart#ToolResultPart":"The successful result of a tool execution. It is explicitly linked back to the originating call by its tool_call_id.\nclass ToolResultPart(BaseModel):\n    type: Literal[\"tool_result\"] = \"tool_result\"\n    tool_call_id: str\n    result: Any  # The structured output from the tool","toolerrorpart#ToolErrorPart":"Used when a tool call fails, either due to a validation error or an execution error. This is the key to the self-correction loop.\nclass ToolErrorPart(BaseModel):\n    type: Literal[\"tool_error\"] = \"tool_error\"\n    tool_call_id: str\n    error_type: Literal[\"VALIDATION\", \"EXECUTION\"]\n    message: str # A human-readable error message for the LLM","3-example-message-flows#3. Example Message Flows":"","31-simple-text-conversation#3.1. Simple Text Conversation":"User Message:\n{\n  \"role\": \"user\",\n  \"parts\": [{ \"type\": \"text\", \"text\": \"Hello, world!\" }]\n}\nAssistant Response (streamed):\n// Stream Packet 1\n{ \"role\": \"assistant\", \"parts\": [{ \"type\": \"text\", \"text\": \"Hello\" }] }\n// Stream Packet 2\n{ \"role\": \"assistant\", \"parts\": [{ \"type\": \"text\", \"text\": \" there!\" }] }","32-successful-tool-call-flow#3.2. Successful Tool Call Flow":"This example shows the full lifecycle, from the agent requesting a tool to receiving the result.1. Assistant requests a tool call:\nThe agent's message contains both explanatory text and a ToolCallPart.\n{\n  \"role\": \"assistant\",\n  \"parts\": [\n    {\n      \"type\": \"text\",\n      \"text\": \"Sure, I can write that file for you. I will now call the tool.\"\n    },\n    {\n      \"type\": \"tool_call\",\n      \"tool_call_id\": \"tc_123\",\n      \"tool_name\": \"write_file\",\n      \"args\": { \"path\": \"/hello.txt\", \"content\": \"Hello, world!\" }\n    }\n  ]\n}\n2. The system provides the tool result:\nA new message is created containing the ToolResultPart. This is sent back to the agent for its next reasoning step.\n{\n  \"role\": \"assistant\",\n  \"parts\": [\n    {\n      \"type\": \"tool_result\",\n      \"tool_call_id\": \"tc_123\",\n      \"result\": { \"status\": \"success\", \"message\": \"File written successfully.\" }\n    }\n  ]\n}\n3. The agent generates its final response:\nAfter receiving the result, the agent formulates its final answer.\n{\n  \"role\": \"assistant\",\n  \"parts\": [\n    {\n      \"type\": \"text\",\n      \"text\": \"I have successfully written the file to `/hello.txt`.\"\n    }\n  ]\n}","33-tool-call-with-self-correction-validation-error#3.3. Tool Call with Self-Correction (Validation Error)":"This flow demonstrates how ToolErrorPart enables the agent to fix its own mistakes.1. Assistant makes a malformed tool call (missing path):\n{\n  \"role\": \"assistant\",\n  \"parts\": [\n    {\n      \"type\": \"tool_call\",\n      \"tool_call_id\": \"tc_456\",\n      \"tool_name\": \"write_file\",\n      \"args\": { \"content\": \"This call is missing the path.\" }\n    }\n  ]\n}\n2. The Orchestrator returns a ToolErrorPart:\nInstead of executing the tool, the system provides a structured validation error.\n{\n  \"role\": \"assistant\",\n  \"parts\": [\n    {\n      \"type\": \"tool_error\",\n      \"tool_call_id\": \"tc_456\",\n      \"error_type\": \"VALIDATION\",\n      \"message\": \"Validation failed for tool 'write_file': Missing required argument 'path'.\"\n    }\n  ]\n}\n3. The agent receives the error and provides a corrected call:\nThe error message is now part of the agent's context. Its Brain sees the mistake and generates a valid call in the next turn.\n{\n  \"role\": \"assistant\",\n  \"parts\": [\n    {\n      \"type\": \"text\",\n      \"text\": \"My apologies, I missed a required parameter. I will correct it now.\"\n    },\n    {\n      \"type\": \"tool_call\",\n      \"tool_call_id\": \"tc_789\",\n      \"tool_name\": \"write_file\",\n      \"args\": {\n        \"path\": \"/corrected.txt\",\n        \"content\": \"This call should now be valid.\"\n      }\n    }\n  ]\n}\nThis new message now proceeds down the successful tool call path.","4-streaming-and-progressive-responses#4. Streaming and Progressive Responses":"To build a truly responsive UI, a client needs to be aware of the agent's progress throughout its turn, not just at the end. This is especially important for multi-step operations like tool calls. AgentX achieves this by streaming a sequence of Message updates for a single logical turn.","41-the-streaming-protocol#4.1. The Streaming Protocol":"The client should not assume a single request will yield a single response. Instead, it should be prepared to receive multiple, distinct Message objects over the same streaming connection. Each object provides a real-time snapshot of the agent's activity.The following sequence diagram illustrates how a client receives progressive updates during a tool call.","42-example-streamed-packets#4.2. Example Streamed Packets":"Here is what the client would see for the successful tool call flow from section 3.2, but as a real-time stream.1. Client sends a request:\nPOST /chat with a user message asking to write a file.2. AgentX streams back the agent's decision to call the tool:\nThe UI can immediately show that a tool is being used.\n{\n  \"role\": \"assistant\",\n  \"id\": \"msg_abc\",\n  \"parts\": [\n    {\n      \"type\": \"tool_call\",\n      \"tool_call_id\": \"tc_123\",\n      \"tool_name\": \"write_file\",\n      \"args\": { \"path\": \"/hello.txt\", \"content\": \"Hello, world!\" }\n    }\n  ]\n}\n3. AgentX streams the result of the tool execution:\nThe UI knows the tool call has completed successfully before the agent has formulated its final textual response.\n{\n  \"role\": \"assistant\",\n  \"id\": \"msg_abc\",\n  \"parts\": [\n    {\n      \"type\": \"tool_result\",\n      \"tool_call_id\": \"tc_123\",\n      \"result\": { \"status\": \"success\", \"message\": \"File written successfully.\" }\n    }\n  ]\n}\n4. AgentX streams the final text response, token by token:\nThe id field links these text chunks back to the same logical message.\n// Packet 1\n{ \"role\": \"assistant\", \"id\": \"msg_abc\", \"parts\": [{ \"type\": \"text\", \"text\": \"I have\" }] }\n// Packet 2\n{ \"role\": \"assistant\", \"id\": \"msg_abc\", \"parts\": [{ \"type\": \"text\", \"text\": \" successfully\" }] }\n// Packet 3\n{ \"role\": \"assistant\", \"id\": \"msg_abc\", \"parts\": [{ \"type\": \"text\", \"text\": \" written the file.\" }] }\nThis progressive, part-based streaming model gives a UI all the information it needs to render a rich, real-time view of the agent's work."}},"/get-started":{"title":"Quick Start","data":{"":"This guide will walk you through running your first AgentX applications, from a simple, single-agent chat to a more complex multi-agent team.","prerequisites#Prerequisites":"Before you begin, make sure you have AgentX installed and have configured your LLM API keys as environment variables (e.g., DEEPSEEK_API_KEY).\nMake sure to set your API keys as environment variables before running the\nexamples.","installation#Installation":"pip install agentx","example-1-simple-chat-single-agent#Example 1: Simple Chat (Single Agent)":"This example demonstrates the simplest use case: a direct conversation with a single, tool-equipped AI assistant. It uses the start_task and task.step() functions for an interactive, turn-by-turn conversation.","1-the-code#1. The Code":"This Python script sets up an interactive chat loop.\n#!/usr/bin/env python3\nimport asyncio\nimport sys\nfrom pathlib import Path\nsys.path.insert(0, str(Path(__file__).parent.parent.parent / \"src\"))\nfrom agentx import start_task\nasync def main():\n    print(\"ü§ñ AgentX Chat (type 'quit' to exit)\\\\n\")\n    task = start_task(\"hi\")\n    user_input = None\n    while not task.is_complete:\n        print(\"ü§ñ Assistant: \", end=\"\", flush=True)\n        async for chunk in task.step(user_input=user_input, stream=True):\n            if chunk.get(\"type\") == \"content\":\n                print(chunk.get(\"content\", \"\"), end=\"\", flush=True)\n        if not task.is_complete:\n            user_input = input(\"üë§ You: \").strip()\nif __name__ == \"__main__\":\n    asyncio.run(main())","2-the-configuration#2. The Configuration":"This YAML file defines the \"team,\" which in this case is just a single agent. It defines the agent's prompt, gives it a web search tool, and configures the LLM.\nname: \"simple_chat\"\ndescription: \"A simple chat example with user, assistant, search, and memory\"\nagents:\n  - name: \"assistant\"\n    description: \"Helpful AI assistant with search capabilities\"\n    prompt_template: \"prompts/assistant.md\"\n    tools: [\"web_search\"]\n    llm_config:\n      provider: \"deepseek\"\n      model: \"deepseek-chat\"\ntools:\n  - name: \"web_search\"\n    type: \"builtin\"\nThe configuration uses YAML for simplicity and readability. You can define\nagents, tools, and their relationships declaratively.","example-2-multi-agent-collaboration#Example 2: Multi-Agent Collaboration":"This example showcases AgentX's multi-agent capabilities. A Writer agent drafts an article, and then a Reviewer agent provides feedback. The handoff between them is managed automatically by the TaskExecutor based on natural language conditions.","1-the-code-1#1. The Code":"#!/usr/bin/env python3\nimport asyncio\nimport sys\nfrom pathlib import Path\nproject_root = Path(__file__).parent.parent.parent\nsys.path.insert(0, str(project_root / \"src\"))\nfrom agentx import execute_task\nasync def main():\n    config_path = str(Path(__file__).parent / \"config\" / \"team.yaml\")\n    prompt = \"Write a short article about remote work benefits.\"\n    async for update in execute_task(prompt, config_path, stream=True):\n        update_type = update.get(\"type\")\n        if update_type == \"content\":\n            print(update[\"content\"], end=\"\", flush=True)\n        elif update_type == \"handoff\":\n            print(f\"\\\\n\\\\nüîÑ HANDOFF: {update['from_agent']} ‚Üí {update['to_agent']}\\\\n\")\nif __name__ == \"__main__\":\n    asyncio.run(main())","2-the-multi-agent-configuration#2. The Multi-Agent Configuration":"This configuration defines two agents and the handoff rules that govern their collaboration:\nname: \"WriterReviewerTeam\"\nagents:\n  - name: writer\n    description: \"Professional content writer for creating high-quality articles\"\n    prompt_template: \"prompts/writer.md\"\n    llm_config:\n      model: deepseek/deepseek-chat\n  - name: reviewer\n    description: \"Quality assurance specialist for reviewing and improving content\"\n    prompt_template: \"prompts/reviewer.md\"\n    llm_config:\n      model: deepseek/deepseek-chat\n# Handoffs using natural language conditions\nhandoffs:\n  - from_agent: \"writer\"\n    to_agent: \"reviewer\"\n    condition: \"draft is complete and ready for review\"\n  - from_agent: \"reviewer\"\n    to_agent: \"writer\"\n    condition: \"feedback has been provided and revisions are needed\"\nNotice how handoffs use natural language conditions! AgentX intelligently\ndetermines when to transfer control between agents.","next-steps#Next Steps":"Explore the Architecture to understand how AgentX works\nCheck out more Examples for advanced use cases\nDive into the API Reference for detailed documentation"}},"/":{"title":"AgentX","data":{"":"The next-generation framework for autonomous multi-agent systemsBuild, orchestrate, and scale AI agents with unprecedented simplicity and power.\nAgentX is designed to make multi-agent AI systems accessible to everyone,\nfrom researchers to enterprise developers.","key-features#Key Features":"ü§ñ Autonomous Agents - Create intelligent agents that can work independently\nüîó Multi-Agent Orchestration - Coordinate complex workflows between multiple agents\nüõ†Ô∏è Tool Integration - Seamlessly integrate with external APIs and services\nüìä Real-time Monitoring - Track agent performance and system health\nüîß Flexible Configuration - Easy YAML-based configuration system\n‚ö° High Performance - Built for scale with async/await patterns","quick-start#Quick Start":"Get started with AgentX in just a few minutes:\npip install agentx\nfrom agentx import Agent, TaskExecutor\n# Create a simple agent\nagent = Agent(\n    name=\"assistant\",\n    model=\"gpt-4\",\n    system_prompt=\"You are a helpful assistant\"\n)\n# Execute a task\nexecutor = TaskExecutor(\"path/to/config.yaml\")\nresult = await executor.run(\"Hello, how can you help me?\")\nprint(result)","why-agentx#Why AgentX?":"Developer-First: Intuitive APIs and comprehensive documentation\nProduction-Ready: Enterprise-grade reliability and monitoring\nExtensible: Plugin architecture for custom functionality\nCommunity-Driven: Open source with active community support","get-started#Get Started":"üìö Quick Start Guide\nGet up and running with AgentX in minutes\nStart Building ‚Üí\nüèóÔ∏è Architecture\nUnderstand the core concepts and design\nLearn More ‚Üí"}},"/arch/01-architecture":{"title":"AgentX System Architecture","data":{"1-executive-summary#1. Executive Summary":"AgentX is an open-source backbone for building secure, observable, and fully autonomous multi-agent systems. A lightweight micro-kernel orchestrates specialised agents, turning a single user request into a coordinated workflow that spans tool execution, memory retrieval, and artifact management‚Äîall within isolated, version-controlled workspaces. Every decision, message, and side effect is captured as a structured event, providing complete auditability and real-time insight into system behaviour.","2-vision--principles#2. Vision & Principles":"","21-project-vision#2.1 Project Vision":"AgentX enables organisations to decompose complex goals into collaborative Teams of agents, each focusing on a well-defined role. A central Orchestrator governs the conversation, selects the next agent to speak, and executes tools on the agents' behalf, while a Task Executor drives the lifecycle of the task itself. The result is a flexible framework that elevates individual agent capabilities into a cohesive, self-optimising system that can learn, adapt, and scale with minimal human intervention.","22-architectural-principles#2.2 Architectural Principles":"The architecture rests on the following foundational principles:\nSeparation of Concerns: Each subsystem has a single, well-defined responsibility, which reduces coupling and simplifies maintenance.\nCentralised Orchestration: A single Orchestrator governs coordination, security, and resource allocation, providing a uniform control plane.\nAgent Autonomy: Agents manage their own reasoning loops and private Brains, delegating only cross-cutting concerns upward.\nEvent-Driven Coordination: Asynchronous, structured events enable scalable, loosely-coupled communication among subsystems.\nConfiguration-Driven Behaviour: Teams, agents, and workflows are defined declaratively, allowing rapid iteration without code changes.\nSecurity by Design: All external interactions pass through audited, policy-enforced channels; least-privilege boundaries are maintained throughout.\nWorkspace Isolation: Every task executes in its own version-controlled workspace, ensuring reproducibility and clean separation of artifacts.","3-system-architecture-overview#3. System Architecture Overview":"The AgentX architecture is composed of four distinct layers:\nClient Layer: Provides the primary user-facing interfaces, including a Command-Line Interface (CLI) for developers, a REST/WebSocket API for programmatic integration, and a web-based Dashboard for real-time monitoring.\nAgentX Core: Contains the essential components for task execution and agent collaboration. The Task Executor drives the workflow, the Orchestrator makes routing decisions, and the Team of Agents performs the reasoning.\nPlatform Services: A suite of shared, pluggable services that support the core. These include the secure Tool Executor, Configuration System, Event Bus, and stateful services for Memory and Observability.\nExternal Systems: Represents all external dependencies, such as LLM Providers, Vector Databases for memory, Git for workspace versioning, and any third-party APIs that tools may call.","4-collaboration-model#4. Collaboration Model":"In AgentX, a Team of collaborating agents is the primary mechanism for executing complex tasks. The core runtime consists of three key components that work in concert to manage the task lifecycle.","40-execution-flow#4.0 Execution Flow":"The AgentX execution flow follows a precise pattern where the TaskExecutor always consults the Orchestrator for routing decisions:\nInitialization: TaskExecutor sets up the workspace and initializes the task context\nRouting Consultation: TaskExecutor calls Orchestrator.decide_next_step(context, last_response) to determine the next action\nAgent Execution: Based on the routing decision, TaskExecutor directly invokes the selected agent via agent.generate_response() or agent.stream_response()\nResult Processing: TaskExecutor receives the agent's response and updates the task context\nCycle Repeat: TaskExecutor returns to step 2, consulting the Orchestrator again with the new response until the task is marked complete\nThis pattern ensures centralized routing intelligence while maintaining clear separation of concerns between task management, routing decisions, and agent execution.","41-key-roles#4.1 Key Roles":"Task Executor: Owns the end-to-end lifecycle of a single task. It acts as the primary workflow engine, responsible for provisioning the workspace, managing the overall task state, and orchestrating the execution flow. The TaskExecutor always consults the Orchestrator for routing decisions via decide_next_step(), then directly invokes the selected agent using generate_response() or stream_response(), and repeats this cycle until task completion.\nOrchestrator: Acts as the centralized coordination service for both tool execution and agent routing. It provides two key functions: (1) makes intelligent routing decisions through decide_next_step() based on current task context and previous agent responses, determining which agent should act next or if the task is complete, and (2) validates tool-call requests against schemas and dispatches them to the secure ToolExecutor.\nAgent: Encapsulates a specialised role (e.g., researcher, writer). It receives control from the Task Executor through direct invocation, reasons with its private Brain, and can invoke the Orchestrator if it needs to execute a tool.","42-execution-modes#4.2 Execution Modes":"AgentX supports two primary modes of execution, offering a trade-off between autonomy and control.1. Autonomous Execution (execute_task)This \"fire-and-forget\" mode is ideal for production. A client submits a task and waits for a final result, while the Task Executor runs the entire multi-agent collaboration autonomously.\n2. Interactive Execution (start_task & step)For debugging or human-in-the-loop workflows, a client can call start_task to get a Task object, then repeatedly call step() to advance the execution one turn at a time.","5-agent-execution-flow#5. Agent Execution Flow":"The AgentX execution flow is built around a clear separation of concerns where the Task Executor coordinates with the Orchestrator for agent routing decisions, while each Agent focuses on its specialized reasoning process. This iterative consultation pattern ensures optimal agent selection based on dynamic task context.","51-prompt-templating#5.1 Prompt Templating":"An agent's core behavior and persona are defined by its system prompt, which is typically loaded from a Jinja2 template file. Before the Task Executor invokes an agent, it injects dynamic context into this template. This ensures the agent is fully aware of the current state of the task. Common context variables include:\nThe full conversation history.\nA list of available tools and their JSON schemas.\nThe initial task objective and any user-provided parameters.\nSummaries or references to artifacts in the workspace.\nThis just-in-time templating allows agents to be both powerful and reusable, adapting their behavior to the specific needs of each task.","52-complete-execution-flow#5.2 Complete Execution Flow":"The complete AgentX execution flow combines the coordination protocol with agent-specific reasoning in a continuous loop:","coordination-loop#Coordination Loop":"Agent Selection: TaskExecutor consults Orchestrator with current context and previous response\nAgent Invocation: TaskExecutor invokes the selected agent's generate_response() or stream_response()\nResponse Collection: TaskExecutor receives the agent's complete response\nRouting Decision: TaskExecutor consults Orchestrator again to determine next action (continue, handoff, or complete)","agent-execution-step-2-detail#Agent Execution (Step 2 Detail)":"When an agent is invoked, it follows its own internal reasoning loop:\nInitial Reasoning: Agent's Brain (LLM) generates a response, potentially including tool calls\nTool Execution: If tools are needed, Agent requests execution from Orchestrator\nOrchestrator validates tool calls against schemas\nInvalid calls trigger self-correction loop with Brain\nValid calls are dispatched to ToolExecutor for secure execution\nResponse Integration: Agent integrates tool results and generates final response\nReturn: Agent returns complete response to TaskExecutor\nThis two-level architecture ensures that routing decisions are centralized and context-aware, while agents can focus on domain-specific reasoning and autonomous tool usage.","53-end-to-end-streaming#5.3 End-to-End Streaming":"To provide maximum transparency and a highly responsive user experience, AgentX is designed for end-to-end streaming. This is more than just streaming the final answer; it means that every significant piece of text generated during the task lifecycle is yielded back to the client in real-time.This is achieved by making streaming the default behavior at every layer of the stack:\nBrain: The Brain streams token-by-token output directly from the underlying LLM provider.\nAgent: The Agent streams its internal monologue, including its reasoning process and its decision to call tools.\nTask Executor: The Task Executor orchestrates these streams, interleaving agent monologues with tool execution status messages and final outputs.\nThis architecture allows a developer or user to watch the entire multi-agent collaboration unfold in real-time, offering unparalleled insight for debugging, monitoring, and human-in-the-loop interaction. It transforms the \"black box\" of agent reasoning into a transparent, observable process.","6-state-and-context-management#6. State and Context Management":"AgentX is designed around the core principle that agents should operate on a rich, durable, and easily accessible context. This is achieved through two tightly integrated components: the Workspace and the Memory System.","61-workspace-a-durable-foundation#6.1 Workspace: A Durable Foundation":"The Workspace is the stateful heart of every task. It is a version-controlled directory that provides the foundation for iterative development, task resumption, and human-in-the-loop collaboration. By persisting every message, artifact, and state change to the workspace, AgentX guarantees full auditability and allows tasks to be paused, inspected, modified, and resumed at any point.Every workspace contains:\nA complete, append-only log of the conversation history (history.jsonl).\nA version-controlled artifacts directory where all agent outputs (code, documents, data) are stored.\nA state.json file capturing the latest state of the Task Executor and all agents.\nThis robust state management is what enables developers to treat tasks not as ephemeral processes, but as durable, long-running workflows that can be debugged, refined, and improved over time.","62-memory-intelligent-context-retrieval#6.2 Memory: Intelligent Context Retrieval":"The Memory acts as the intelligent, unified gateway for retrieving contextual data from the Workspace. It is more than a simple wrapper around a vector database; it is the sole entry point for agents to perform intelligent data fetching, ensuring they have the most relevant information without exceeding token limits.Its responsibilities are twofold:\nContext Ingestion: It automatically captures and indexes conversational history, agent-generated artifacts, and other designated data sources from the Workspace into a long-term, searchable store.\nIntelligent Retrieval: It provides a simple query interface for agents to retrieve contextually relevant information. The system handles the complexity of searching across different data types and uses semantic ranking to return only the most salient facts.\nBy abstracting away the complexities of data storage and retrieval, the Memory System allows agents to remain focused on reasoning, while ensuring their prompts are always grounded with high-quality, relevant context from the Workspace.","63-example-scenario-context-aware-writing#6.3 Example Scenario: Context-Aware Writing":"To illustrate how these components work together, consider a Writer agent tasked with drafting a report. A Researcher agent has already run, populating the Workspace with dozens of source documents.\nInitial State: The Workspace contains all source documents as artifacts (e.g., source_01.txt, source_02.txt, etc.). The Memory System has indexed the content of each of these sources. The main report is still empty.\nWriting the First Section: The Writer is tasked with \"Write the introduction.\" It queries the Memory System: \"Find sources relevant to the overall topic.\" The Memory System returns the most relevant source documents. The Writer uses them to draft the introduction, which is then saved back to the Workspace as report_v1.md.\nPreventing Redundancy: When the Writer is next tasked with \"Write the 'History of AI' section,\" it performs a more sophisticated query: \"Find sources related to 'the history of AI' that are not already referenced in report_v1.md.\"\nIntelligent Retrieval: The Memory System understands this query. It performs a semantic search for \"history of AI\" across all source documents, but it also performs a negative semantic search, filtering out any sources whose content closely matches what is already in report_v1.md.\nGrounded Response: The Memory System returns a fresh, relevant, and unused set of sources. The Writer can now draft the new section with confidence, knowing it is not repeating information.\nThis scenario demonstrates how the combination of a durable Workspace and an intelligent Memory System enables agents to perform complex, stateful tasks that would be impossible with a simple conversational context window.","7-platform-services#7. Platform Services":"Platform Services provide common capabilities that sit outside the tight execution loop yet remain essential to every task. They are deployed as shared, multi-tenant components and accessed via well-defined APIs, allowing the core runtime to stay lightweight while still benefiting from robust storage, configuration, and monitoring facilities.","71-configuration-system#7.1 Configuration System":"The Configuration System is the single source of truth for teams, agents, tools, and runtime policies. It loads declarative YAML files, validates them against versioned schemas, and exposes the resulting objects to the Task Executor and Orchestrator at startup or on hot-reload.","72-event-bus#7.2 Event Bus":"All significant actions in the framework emit structured events that flow through the Event Bus. This design decouples producers from consumers, enabling real-time monitoring, auditing, and external integrations without burdening the hot code-path.","73-memory-system-infrastructure#7.3 Memory System Infrastructure":"While Section 6 described the Memory System from a business logic perspective, this section focuses on its infrastructure implementation. The Memory System uses a pluggable backend architecture that abstracts away the complexities of different memory storage implementations.Implementation Architecture:\nMemory Backend Interface: A standardized interface that allows different memory providers (mem0, vector databases, etc.) to be plugged in seamlessly\nmem0 Integration: The default backend leverages mem0 for intelligent memory management, providing automatic memory extraction, storage, and retrieval\nVector Database Support: Direct integration with vector databases for semantic search capabilities\nMemory Factory Pattern: A factory that instantiates the appropriate memory backend based on configuration\nKey Infrastructure Features:\nAutomatic Indexing: Background processes that continuously index new content from workspaces\nScalable Storage: Support for both local and distributed memory storage backends\nMemory Lifecycle Management: Automatic cleanup, archival, and optimization of stored memories\nProvider Abstraction: Clean separation between the memory interface and underlying storage technology\nThis infrastructure design ensures that the Memory System can scale from development environments using local storage to production deployments using enterprise-grade vector databases, all without changing the business logic layer.","74-observability#7.4 Observability":"The Observability service provides real-time insight into the inner workings of the AgentX framework. It subscribes to the Event Bus to receive a live stream of all system events‚Äîfrom task creation to agent handoffs to tool executions. This data is then exposed through a built-in web dashboard, allowing developers to:\nVisually trace the entire lifecycle of a task.\nInspect the contents of any agent's workspace, including conversation history and artifacts.\nDebug complex multi-agent interactions in real-time.\nBy making the system transparent by default, the Observability service dramatically reduces the time required to build, test, and refine sophisticated agent-based workflows.","8-builtin-tools#8. Builtin Tools":"Builtin Tools extend AgentX with first-class capabilities without requiring users to write custom plugins. They are registered automatically at startup and are available to any agent subject to security policy. These tools are designed to be general-purpose and cover the most common needs of autonomous agents.Key builtin tools include:\nStorage Tools: Clean file operations that use the storage layer, providing secure workspace-scoped file management with proper isolation and version control. Includes read_file, write_file, list_directory, delete_file, and other essential file operations.\nWeb Tools: Advanced web capabilities including web_search, extract_content for web scraping, and automate_browser for AI-driven browser automation using natural language instructions.\nMemory Tools: Direct interface to the Memory system for storing and retrieving contextual information across task sessions.\nContext Tools: Tools for managing and updating task context variables, allowing agents to maintain and share state information.\nPlanning Tools: Sophisticated task planning and execution tracking tools that help agents break down complex tasks into manageable phases.\nSearch Tools: Web search capabilities using multiple search engines (Google, Bing, DuckDuckGo) with configurable parameters.\nBy providing these foundational capabilities, AgentX ensures that developers can build powerful and effective agent teams from day one.","9-extensibility#9. Extensibility":"AgentX is designed as a production-ready backbone, which means it must be extensible at every layer.\nAdding LLM Providers: The Brain component uses a provider model that allows new LLMs to be integrated by implementing a simple, common interface.\nCustom Tools: Developers can add their own tools by decorating Python functions. These are registered alongside builtin tools and exposed to agents in the same way.\nMCP Tools & API Integration: For complex integrations, the framework supports Multi-Container Platform (MCP) tools, which run in secure sandboxes, allowing safe interaction with enterprise APIs and SaaS platforms.","10-the-future-of-agentx#10. The Future of AgentX":"AgentX will continue to evolve along three pillars: performance, interoperability, and safety. Upcoming priorities include native support for streaming multimodal models, tighter integration with external knowledge graphs to improve grounding, and progressive guardrail policies that adapt to organisational compliance requirements. We also plan to introduce a plug-and-play planning module so that teams can experiment with alternative orchestration strategies without modifying core code. Finally, deeper observability hooks‚Äîspanning trace-level token accounting through to high-level outcome metrics‚Äîwill help users fine-tune cost, latency, and quality trade-offs."}}}